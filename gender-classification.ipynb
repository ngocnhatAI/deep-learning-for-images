{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78157452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dataset import *\n",
    "from transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c66003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 8000\n",
      "Validation dataset size: 1000\n",
      "Test dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "data_path = r\"C:\\Users\\Admin\\Desktop\\FINAL-IMAGE-PROCESSING\\deep-learning-for-images\\data\\gender-classification\"\n",
    "\n",
    "train_transform = gender_transforms(is_train=True)\n",
    "val_transform = gender_transforms(is_train=False)\n",
    "test_transform = gender_transforms(is_train=False)\n",
    "\n",
    "# Datasets\n",
    "train_dataset = GenderDataset(\n",
    "    root_dir=os.path.join(data_path, 'Train'),\n",
    "    transform=train_transform\n",
    ")\n",
    "val_dataset = GenderDataset(\n",
    "    root_dir=os.path.join(data_path, 'Val'),\n",
    "    transform=val_transform\n",
    ")\n",
    "test_dataset = GenderDataset(\n",
    "    root_dir=os.path.join(data_path),\n",
    "    transform=test_transform,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77c7526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  # (batch_size, 3, H, W)\n",
    "print(labels.shape)  # (batch_size,)\n",
    "print(images[0].shape)\n",
    "print(labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e391248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet-18 model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final fully connected layer for binary classification (male/female)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0397019",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# TRAIN IN ONE EPOCH FOR TESTING\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c2e1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 46.30%\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on validation set: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
